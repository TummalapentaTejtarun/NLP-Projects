{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q8prmuV9bR8"
      },
      "outputs": [],
      "source": [
        "a_original=\"Big data refers to extremely large and diverse collections of structured, unstructured, and semi-structured data that continues to grow exponentially over time. These datasets are so huge and complex in volume, velocity, and variety, that traditional data management systems cannot store, process, and analyze them.\"\n",
        "a=\"Big data refers to extremely large and diverse collections of structured, unstructured, and semi-structured data that continues to grow exponentially over time. These datasets are so huge and complex in volume, velocity, and variety, that traditional data management systems cannot store, process, and analyze them.\"\n",
        "a=a.lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "a=re.sub(r'\\d+','',a)   #removes digits\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLyDd4LRBCoY",
        "outputId": "1da7748a-9ee0-449b-94dd-c55fd741cbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big data refers to extremely large and diverse collections of structured, unstructured, and semi-structured data that continues to grow exponentially over time. these datasets are so huge and complex in volume, velocity, and variety, that traditional data management systems cannot store, process, and analyze them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AjUjBIvYBCf4",
        "outputId": "56825583-210f-42ef-fc87-5b5a570542f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=a.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KChymWrB7dW",
        "outputId": "db25a111-467e-4f47-8f83-fbb718c67c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "big data refers to extremely large and diverse collections of structured unstructured and semistructured data that continues to grow exponentially over time these datasets are so huge and complex in volume velocity and variety that traditional data management systems cannot store process and analyze them\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=\" \".join([token for token in a.split()])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eUBkq3ViB7Zv",
        "outputId": "18a10a94-0a33-4a02-e001-46447e687e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'big data refers to extremely large and diverse collections of structured unstructured and semistructured data that continues to grow exponentially over time these datasets are so huge and complex in volume velocity and variety that traditional data management systems cannot store process and analyze them'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "import nltk\n",
        "#from nltk.a import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words_nltk=set(nltk.corpus.stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ3wMqSCB7U_",
        "outputId": "1ce0866e-fe71-46a0-db23-3eec985811c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VkuQuqXZDZLM",
        "outputId": "ead61b2a-5306-446c-f2bb-8779431cfa66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus_nltk=word_tokenize(a)\n",
        "print(tokenized_corpus_nltk )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov1gjMR0Df9D",
        "outputId": "ebabdd76-d686-487d-9aac-fe75d50deb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['big', 'data', 'refers', 'to', 'extremely', 'large', 'and', 'diverse', 'collections', 'of', 'structured', 'unstructured', 'and', 'semistructured', 'data', 'that', 'continues', 'to', 'grow', 'exponentially', 'over', 'time', 'these', 'datasets', 'are', 'so', 'huge', 'and', 'complex', 'in', 'volume', 'velocity', 'and', 'variety', 'that', 'traditional', 'data', 'management', 'systems', 'can', 'not', 'store', 'process', 'and', 'analyze', 'them']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_corpus_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3tONHVSFZ8Z",
        "outputId": "84d7e332-2b35-4365-e693-e338b1b79a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus_without_stopwords_nltk=[i for i in tokenized_corpus_nltk if i not in stop_words_nltk]\n",
        "print(tokenized_corpus_without_stopwords_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGUsyCYEFoLI",
        "outputId": "874587f6-7f00-4dc2-fe64-59e1b31e66a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['big', 'data', 'refers', 'extremely', 'large', 'diverse', 'collections', 'structured', 'unstructured', 'semistructured', 'data', 'continues', 'grow', 'exponentially', 'time', 'datasets', 'huge', 'complex', 'volume', 'velocity', 'variety', 'traditional', 'data', 'management', 'systems', 'store', 'process', 'analyze']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_corpus_without_stopwords_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwcT-uFRH4et",
        "outputId": "d675b525-e05a-4e72-d28c-3a67b2aa1ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import spacy\n",
        "spacy_model=spacy.load('en_core_web_sm')\n",
        "stopwords_spacy=spacy_model.Defaults.stop_words\n",
        "print(\"\\nSpacy\")\n",
        "tokenized_corpus_spacy=word_tokenize(a)\n",
        "print(\"Tokenized corpus:\\n\",tokenized_corpus_spacy)\n",
        "tokens_without_sw=[word for word in tokenized_corpus_spacy if not word in stopwords_spacy]\n",
        "print(\"Tokenized corpus without corpus:\\n\",tokens_without_sw)\n",
        "print(\"Difference between NLTK and spacy output:\\n\",set(tokenized_corpus_spacy)-set(tokens_without_sw))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxXHf7svH92c",
        "outputId": "43f0c41b-df19-45d8-f20d-9752711a968a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Spacy\n",
            "Tokenized corpus:\n",
            " ['big', 'data', 'refers', 'to', 'extremely', 'large', 'and', 'diverse', 'collections', 'of', 'structured', 'unstructured', 'and', 'semistructured', 'data', 'that', 'continues', 'to', 'grow', 'exponentially', 'over', 'time', 'these', 'datasets', 'are', 'so', 'huge', 'and', 'complex', 'in', 'volume', 'velocity', 'and', 'variety', 'that', 'traditional', 'data', 'management', 'systems', 'can', 'not', 'store', 'process', 'and', 'analyze', 'them']\n",
            "Tokenized corpus without corpus:\n",
            " ['big', 'data', 'refers', 'extremely', 'large', 'diverse', 'collections', 'structured', 'unstructured', 'semistructured', 'data', 'continues', 'grow', 'exponentially', 'time', 'datasets', 'huge', 'complex', 'volume', 'velocity', 'variety', 'traditional', 'data', 'management', 'systems', 'store', 'process', 'analyze']\n",
            "Difference between NLTK and spacy output:\n",
            " {'so', 'are', 'to', 'over', 'them', 'can', 'in', 'that', 'and', 'not', 'these', 'of'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_corpus_spacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLMHrp-pKi7v",
        "outputId": "2eb4878c-f35b-4e07-f4a7-e802bdb27a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens_without_sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1X_Q1H8Kmi2",
        "outputId": "f009d3ec-c1c3-4a62-a013-05ee7541772e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer=PorterStemmer()\n",
        "print(\"Befor Stemming:\\n\",a)\n",
        "print(\"After Stemming:\")\n",
        "for word in tokenized_corpus_nltk:\n",
        "    print(stemmer.stem(word),end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWrsiKfDL-4c",
        "outputId": "9404d838-56b8-432a-9003-8b118a45bd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Befor Stemming:\n",
            " big data refers to extremely large and diverse collections of structured unstructured and semistructured data that continues to grow exponentially over time these datasets are so huge and complex in volume velocity and variety that traditional data management systems cannot store process and analyze them\n",
            "After Stemming:\n",
            "big data refer to extrem larg and divers collect of structur unstructur and semistructur data that continu to grow exponenti over time these dataset are so huge and complex in volum veloc and varieti that tradit data manag system can not store process and analyz them "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHEXTJ8QM5Ta",
        "outputId": "8f7ddb87-808e-485f-e0d0-2d2587f2a057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "print(\"rocks :\",lemmatizer.lemmatize(\"rocks\"))\n",
        "print(\"corpora :\",lemmatizer.lemmatize(\"corpora\"))\n",
        "# a denotes adjective in \"pos\"\n",
        "print(\"better :\",lemmatizer.lemmatize(\"better\",pos=\"a\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFOjzMxFO_Q3",
        "outputId": "6a32e133-d3c1-41fa-9e5f-5439b8e9331d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\",pos='a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E8uM7fIGPYtH",
        "outputId": "61354a79-6fcf-4e4b-f31a-81e1f88979b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"working\",pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lW3PsP5-PkiG",
        "outputId": "904c61ab-f81e-47fe-f9f6-2d6251bf18cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'work'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\",pos='a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "43KYC6-wQqRE",
        "outputId": "54228eeb-e45f-4c44-8a80-ed4991c18a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}